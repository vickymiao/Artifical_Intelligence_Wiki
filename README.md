# Artifical_Intelligence_Wiki

### :smiley: Artificial Intelligence

***Aritifical Intelligence***: Any techniques that enable computers to mimic human behavior.<br>
***Machine Learining***: Subset of AI that use statisticual methods to learn from data, identify patterns and make decisions. <br>
***Deep Learning***: Subset of ML that is based on artificial neural networks.<br>

Manufacturing, retailing, transporation, finance, healthcare, and virtually every other industry is taking advantage of AI to transform thier core process and business models. The effects of AI will be maginified in the coming decade. <br>

Constructing machine learning models requries domain knowledge, mathematical expertise, and computer science skill.

### :star: Standard Machine Learning Process
1. Identify business problems
2. Collect data from various resources
3. Lable target (Supervised machine learning)
4. Extract features that will be used as the input to train models
5. Partition data into training, validation and holdout data.
6. Determine model evaluation criteria
7. Train model
8. Analyze model outcomes / model selection
9. Deploy model

### :boom: Big Data
Big data refers to volume, velocity, and varity of data that is available.
* Volume: the amount of data immense.
* Velocity: the speed of data
* Variety: the different types of data, strucutre, as well as, unstructured

### Classification
Classification is a technique by which you determine to what group a certain observation belongs.

### Confusion Matrix
After training each classification model, the resulting confusion matrix shows how accurately the model categroized each record and where it might be making errors.

<img src = 'https://miro.medium.com/max/356/1*Z54JgbS4DUwWSknhDCvNTQ.png'>

### Cross-Validation
Cross-validation is an extension of the training, validation, and holdout (test sets) process that minimise the sampling bias of machine learning models. <br>
<img src='https://3gp10c1vpy442j63me73gy3s-wpengine.netdna-ssl.com/wp-content/uploads/2018/03/Screen-Shot-2018-03-22-at-1.22.04-PM.png'>
With corss validation, the non-holdout data was split into five buckets, it is called '5-fold cross validation'. We then use one protion of the data for validation, and the remainder as training dataset.
After that, five iterations of a model is built based on the training data set and is tested with the validation dataset. Then compute the average performance of the model on each of the validation partitions.<br>
<img scr='https://3gp10c1vpy442j63me73gy3s-wpengine.netdna-ssl.com/wp-content/uploads/2018/03/Screen-Shot-2018-03-21-at-4.26.53-PM.png'>

